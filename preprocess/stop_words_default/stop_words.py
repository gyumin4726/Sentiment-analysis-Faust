import re
import nltk
from nltk.corpus import stopwords

# ë¶ˆìš©ì–´ ë‹¤ìš´ë¡œë“œ (ìµœì´ˆ ì‹¤í–‰ ì‹œ í•„ìš”)
nltk.download("stopwords")

# ì˜ì–´ ë¶ˆìš©ì–´ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
stop_words = set(stopwords.words("english"))

def remove_stopwords(text_lines):
    """
    ëŒ€ì‚¬ì—ì„œ ë¶ˆìš©ì–´ë¥¼ ì œê±°í•˜ëŠ” í•¨ìˆ˜
    """
    cleaned_dialogues = []

    for line in text_lines:
        words = line.strip().split()  # ë‹¨ì–´ë³„ë¡œ ë¶„í• 
        filtered_words = [word for word in words if word.lower() not in stop_words]  # ë¶ˆìš©ì–´ ì œê±°
        cleaned_line = " ".join(filtered_words)  # ë‹¤ì‹œ ë¬¸ì¥ìœ¼ë¡œ ì¡°í•©
        if cleaned_line:  # ë¹ˆ ì¤„ì€ ì¶”ê°€í•˜ì§€ ì•ŠìŒ
            cleaned_dialogues.append(cleaned_line)

    return cleaned_dialogues

# ğŸ“Œ ìˆ˜ì •ëœ íŒŒì¼ ê²½ë¡œ (ë°±ìŠ¬ë˜ì‹œ ë¬¸ì œ í•´ê²°: r"" ë˜ëŠ” os.path ì‚¬ìš©)
faust_file_path = r"C:\Users\ë°•ê·œë¯¼\OneDrive - KookminUNIV\ë°”íƒ• í™”ë©´\ë¹…ë°ì´í„° ìµœì‹ ê¸°ìˆ \Sentiment-analysis-Faust\preprocess\faust_dialogues.txt"
mephi_file_path = r"C:\Users\ë°•ê·œë¯¼\OneDrive - KookminUNIV\ë°”íƒ• í™”ë©´\ë¹…ë°ì´í„° ìµœì‹ ê¸°ìˆ \Sentiment-analysis-Faust\preprocess\mephi_dialogues.txt"

with open(faust_file_path, "r", encoding="utf-8") as f:
    faust_text = f.readlines()

with open(mephi_file_path, "r", encoding="utf-8") as f:
    mephi_text = f.readlines()

# ë¶ˆìš©ì–´ ì œê±° ì ìš©
cleaned_faust_no_stopwords = remove_stopwords(faust_text)
cleaned_mephi_no_stopwords = remove_stopwords(mephi_text)

# ê²°ê³¼ ì €ì¥
faust_no_stopwords_path = "faust_cleaned_no_stopwords.txt"
mephi_no_stopwords_path = "mephi_cleaned_no_stopwords.txt"

with open(faust_no_stopwords_path, "w", encoding="utf-8") as f:
    f.write("\n".join(cleaned_faust_no_stopwords))

with open(mephi_no_stopwords_path, "w", encoding="utf-8") as f:
    f.write("\n".join(cleaned_mephi_no_stopwords))

print("âœ… ë¶ˆìš©ì–´ ì œê±° ì™„ë£Œ! ì •ë¦¬ëœ íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
