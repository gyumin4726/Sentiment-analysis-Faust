from gensim.models import Word2Vec
import numpy as np

# íŒŒì¼ ì—´ê¸°
with open(r"C:\Users\ë°•ê·œë¯¼\OneDrive - KookminUNIV\ë°”íƒ• í™”ë©´\ë¹…ë°ì´í„° ìµœì‹ ê¸°ìˆ \Sentiment-analysis-Faust\preprocess\THREE_NLTK_stop_words\faust_dialogues_final.txt", "r", encoding="utf-8") as f:
    faust_lines = f.readlines()
with open(r"C:\Users\ë°•ê·œë¯¼\OneDrive - KookminUNIV\ë°”íƒ• í™”ë©´\ë¹…ë°ì´í„° ìµœì‹ ê¸°ìˆ \Sentiment-analysis-Faust\preprocess\THREE_NLTK_stop_words\mephisto_dialogues_final.txt", "r", encoding="utf-8") as f:
    mephi_lines = f.readlines()

# âœ… í† í°í™”ëœ ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸ (ë¶ˆìš©ì–´ ì œê±° + ì „ì²˜ë¦¬ëœ ë¬¸ì¥)
tokenized_lines_faust = [line.strip().split() for line in faust_lines if line.strip()]
# âœ… í† í°í™”ëœ ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸ (ë¶ˆìš©ì–´ ì œê±° + ì „ì²˜ë¦¬ëœ ë¬¸ì¥)
tokenized_lines_mephi = [line.strip().split() for line in mephi_lines if line.strip()]


# âœ… Word2Vec í•™ìŠµ
model1 = Word2Vec(
    sentences=tokenized_lines_faust,
    vector_size=100,
    window=5,
    min_count=2,
    workers=4
)

# âœ… Word2Vec í•™ìŠµ
model2 = Word2Vec(
    sentences=tokenized_lines_mephi,
    vector_size=100,
    window=5,
    min_count=2,
    workers=4
)

# âœ… ì—°ê´€ ë‹¨ì–´ ì¶œë ¥
print("ğŸ” 'íŒŒìš°ìŠ¤íŠ¸ì˜ love'ì™€ ìœ ì‚¬í•œ ë‹¨ì–´:")
for word, score in model1.wv.most_similar('love', topn=10):
    print(f"{word:10} â†’ {score:.4f}")

# âœ… ì—°ê´€ ë‹¨ì–´ ì¶œë ¥
print("ğŸ” 'ë©”í”¼ìŠ¤í† í ë ˆìŠ¤ì˜ devil'ê³¼ ìœ ì‚¬í•œ ë‹¨ì–´:")
for word, score in model2.wv.most_similar('devil', topn=10):
    print(f"{word:10} â†’ {score:.4f}")


# 2. ê³µí†µ íŒŒë¼ë¯¸í„° ì„¤ì •
vector_size = model1.vector_size
merged_model = Word2Vec(vector_size=vector_size, min_count=1)  # ë¹ˆ ëª¨ë¸ ìƒì„±

# 3. ë‹¨ì–´ ì§‘í•© ê²°í•©
all_words = set(model1.wv.key_to_index.keys()) | set(model2.wv.key_to_index.keys())

# 4. ë‹¨ì–´ â†’ ë²¡í„° ì„¤ì •
vectors = []
vocab = []

for word in all_words:
    vecs = []
    if word in model1.wv:
        vecs.append(model1.wv[word])
    if word in model2.wv:
        vecs.append(model2.wv[word])
    avg_vec = np.mean(vecs, axis=0)
    vectors.append(avg_vec)
    vocab.append(word)

# 5. ëª¨ë¸ì— ë‹¨ì–´ì™€ ë²¡í„° ìˆ˜ë™ ì‚½ì…
merged_model.build_vocab([vocab])
merged_model.wv.vectors = np.array(vectors)

# 6. ì €ì¥
merged_model.save("../word2vec/merged_w2v.model")
print("âœ… í†µí•© Word2Vec ëª¨ë¸ ì €ì¥ ì™„ë£Œ: merged_w2v.model")
