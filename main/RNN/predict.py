import torch
import re

def tokenize(text):
    return re.findall(r"\b\w+\b", text.lower())

def encode(tokens, vocab):
    return [vocab.get(token, vocab["<unk>"]) for token in tokens]

def predict_sentiment(sentence, model, vocab, label_names, max_len=50, device='cpu'):
    model.eval()
    tokens = tokenize(sentence)
    indexed = encode(tokens, vocab)[:max_len]
    indexed += [vocab["<pad>"]] * (max_len - len(indexed))  # padding

    tensor = torch.LongTensor(indexed).unsqueeze(0).to(device)  # [1, seq_len]

    with torch.no_grad():
        output = model(tensor)
        probs = torch.softmax(output, dim=1).squeeze()  # [output_dim]

    predicted_idx = torch.argmax(probs).item()
    return label_names[predicted_idx], probs[predicted_idx].item(), probs


# âœ… ì§ì ‘ ì‹¤í–‰ í…ŒìŠ¤íŠ¸ (ì˜ˆ: íŒŒìš°ìŠ¤íŠ¸ ë¬¸ì¥)
if __name__ == "__main__":
    from model import RNN
    import torch.nn as nn
    import torch.optim as optim
    import os

    # ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    checkpoint = torch.load("../checkpoint/saved_rnn_model.pth", map_location=device)
    vocab = checkpoint['vocab']
    label_names = checkpoint['label_names']

    embedding_dim = 100
    hidden_dim = 128
    max_len = 50
    input_dim = len(vocab)
    output_dim = len(label_names)
    pad_idx = vocab["<pad>"]

    model = RNN(input_dim, embedding_dim, hidden_dim, output_dim, pad_idx)
    model.load_state_dict(checkpoint['model_state_dict'])
    model = model.to(device)

    # ì˜ˆì¸¡í•  ë¬¸ì¥
    sentence = "confess forth wander steps slight obstacle controlledâ€” wizardsfoot threshold made"

    # ì˜ˆì¸¡
    label, confidence, probs = predict_sentiment(sentence, model, vocab, label_names, max_len=max_len, device=device)

    # ì¶œë ¥
    print(f"\nğŸ’¬ ì˜ˆì¸¡ ë¬¸ì¥: {sentence}")
    print(f"ğŸ” ì˜ˆì¸¡ ê°ì •: {label} (í™•ë¥ : {confidence:.4f})\n")

    print("ğŸ“Š ê°ì •ë³„ í™•ë¥ :")
    for i, p in enumerate(probs):
        print(f"{label_names[i]:<15}: {p.item():.4f}")
